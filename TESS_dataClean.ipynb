{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92775b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e8fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy.io import fits \n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "from astropy.visualization import time_support\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "from scipy.stats import sigmaclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85320cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClean(filename): \n",
    "    \"\"\" This function will remove nan values from TESS \n",
    "        20 second lightcurve data and correct time values\n",
    "        Stage: complete\"\"\"\n",
    "    \n",
    "    #Create an array of time and flux data with nans removed    \n",
    "    with fits.open(filename, mode=\"readonly\") as hdulist:\n",
    "        raw_time = hdulist[1].data['TIME']\n",
    "        raw_flux = hdulist[1].data['PDCSAP_FLUX']\n",
    "        raw_err = hdulist[1].data['PDCSAP_FLUX_ERR']\n",
    "    data = np.vstack((raw_time, raw_flux, raw_err))\n",
    "    nonan_data = data[:, ~np.isnan(data).any(axis=0)]\n",
    "\n",
    "    #Apply time correction \n",
    "    times = nonan_data[0]\n",
    "    flux = nonan_data[1]\n",
    "    error = nonan_data[2]\n",
    "    t_corr = []\n",
    "    for i in times:\n",
    "        r = i + 2457000\n",
    "        t_corr.append(r)\n",
    "    time = Time(t_corr, format = 'jd', scale = 'utc')\n",
    "    time.format = 'iso'\n",
    "    \n",
    "    #Create arrays of cleaned data\n",
    "    time = np.array(time)\n",
    "    flux = np.array(flux)\n",
    "    err = np.array(error)\n",
    "    \n",
    "    #Return cleaned data\n",
    "    return[time,flux,err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55076139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Qcurve(cleaned_data):\n",
    "    \"\"\" This function will take cleaned data and dataframes of quiescent light curve\n",
    "    as well as flaring light curve values\n",
    "    Stage: complete\"\"\"\n",
    "\n",
    "    #Identify quiescent light curve\n",
    "    flux_smooth = sig.savgol_filter(cleaned_data[1], 1400, 3) #my opinion of the best parameters for this data\n",
    "    index = np.where(cleaned_data[1] < (flux_smooth + (3*cleaned_data[2]))) #using 3 as the significance for the error for now\n",
    "    q_time = cleaned_data[0][index] # time associated w/ quiescent flux\n",
    "    q_flux = sig.savgol_filter(cleaned_data[1][index],2000,3) # quiescent flux\n",
    "    ind2 = np.where(q_flux) #index created to assure lengths of data sets are equal\n",
    "    \n",
    "    #Set and index variables\n",
    "    fluxes = cleaned_data[1]\n",
    "    times = cleaned_data[0]\n",
    "    F_err = cleaned_data[2] \n",
    "    flux_list = fluxes[ind2]\n",
    "    time_list = times[ind2]\n",
    "    err_list = F_err[ind2]\n",
    "\n",
    "    #Ensure lists are same size for flare and quiescent data & have same timestamps at same indices\n",
    "    qIndex = np.where(q_time) \n",
    "    err_list = err_list[qIndex]\n",
    "    q_time = times[qIndex]\n",
    "    q_flux = sig.savgol_filter(flux_list[qIndex],2000,3)\n",
    "    \n",
    "    #Create dataframes of Quiescent and Flaring lightcurves\n",
    "    quiescence = pd.DataFrame({\n",
    "                            'Time': q_time,\n",
    "                            'Quiescent Flux':q_flux\n",
    "    })\n",
    "\n",
    "    cd = pd.DataFrame({\n",
    "                                'Time': time_list[qIndex],\n",
    "                                'Flux':flux_list[qIndex],\n",
    "                                'Flux Error': err_list[qIndex]\n",
    "    })\n",
    "    return[quiescence,cd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf70c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ix_ranges(ix, buffer=False):\n",
    "    \"\"\" Finds indexes in the range.\n",
    "    \n",
    "        From MC GALEX function defs\"\"\"\n",
    "    \n",
    "    foo, bar = [], []\n",
    "    for n, i in enumerate(ix):\n",
    "        if len(bar) == 0 or bar[-1] == i-1:\n",
    "            bar += [i]\n",
    "        else:\n",
    "            if buffer:\n",
    "                bar.append(min(bar)-1)\n",
    "                bar.append(max(bar)+1)\n",
    "            foo += [np.sort(bar).tolist()]\n",
    "            bar = [i]\n",
    "        if n == len(ix)-1:\n",
    "            if buffer:\n",
    "                bar.append(min(bar)-1)\n",
    "                bar.append(max(bar)+1)\n",
    "            foo += [np.sort(bar).tolist()]\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inff(lc, clipsigma=3, quiet=True, band='NUV',\n",
    "             binsize=30.):\n",
    "    \"\"\" Calculates the Instantaneous Non-Flare Flux values.\n",
    "    \n",
    "        From MC GALEX function defs\"\"\"\n",
    "    \n",
    "    sclip = sigma_clip(np.array(lc['Flux']), sigma=clipsigma)\n",
    "    inff = np.ma.median(sclip)\n",
    "    inff_err = np.sqrt(inff*len(sclip)*binsize)/(len(sclip)*binsize)\n",
    "    if inff and not quiet:\n",
    "        print('Quiescent at {m} AB mag.'.format(m=gt.counts2mag(inff, band)))\n",
    "    return inff, inff_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a795244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flareFinder(curve,q_curve,sig):\n",
    "    \"\"\"This function will run through the data to find \n",
    "    flares and ranges of flares. This function will return\n",
    "    a table of flares ranges. \n",
    "    \n",
    "    Adapted from MC GALEX function defs.\n",
    "    Stage: debugging\"\"\"\n",
    "    \n",
    "    fluxes = curve['Flux']\n",
    "    for flux in fluxes:\n",
    "        ix = np.where(((np.array(curve['Flux'].values)-(sig*np.array(curve['Flux Error'].values)) >= q_curve['Quiescent Flux'])))[0]\n",
    "        flareFlux = ix\n",
    "        flux_ix = []\n",
    "        \n",
    "        for ix_range in find_ix_ranges(ix):\n",
    "            # go backwards\n",
    "            consec = 0 \n",
    "            err = curve.iloc[ix_range[0]]['Flux Error'] \n",
    "            \n",
    "            #while flux - err > quiescence, find 2 consecutive points withing quiescent curve\n",
    "            while any(curve.iloc[ix_range[0]]['Flux']-err >= q_curve['Quiescent Flux']) & ix_range[0] > 0 or (consec < 1 & ix_range[0] >0):\n",
    "                err = curve.iloc[ix_range[0]]['Flux Error']\n",
    "                \n",
    "                #if flux < q add 1 to consecutive points\n",
    "                if any(curve.iloc[ix_range[0]]['Flux']- err < q_curve['Quiescent Flux']) :\n",
    "                    consec +=1\n",
    "                else: \n",
    "                    consec = 0\n",
    "                if (curve.iloc[ix_range[0]+1]['Flux']-curve.iloc[ix_range[0]]['Flux']) > 1000: #don't understand this statement much, how do I get it to break correctly?\n",
    "                    break               \n",
    "                ix_range = [ix_range[0] - 1] + ix_range\n",
    "                \n",
    "                # go forwards\n",
    "            consec = 0 \n",
    "            err = curve.iloc[ix_range[-1]]['Flux Error']\n",
    "            while any(curve.iloc[ix_range[-1]]['Flux']-err >= q_curve['Quiescent Flux']) & ix_range[-1] != len(curve)-1 or (consec <1 & ix_range[-1]!= len(curve)-1):\n",
    "                err = curve.iloc[ix_range[-1]]['Flux Error']\n",
    "                if any(curve.iloc[ix_range[-1]]['Flux']-err < q_curve['Quiescent Flux']):\n",
    "                    consec += 1\n",
    "                else: \n",
    "                    consec = 0\n",
    "                if curve.iloc[ix_range[-1]+1]['Flux']-curve.iloc[ix_range[-1]]['Flux'] > 1000: #don't understand this statement much, how do I get it to break correctly?\n",
    "                    break\n",
    "                ix_range = ix_range + [ix_range[-1] + 1]\n",
    "                \n",
    "            flux_ix += ix_range\n",
    "        ix = np.unique(flux_ix)\n",
    "        flare_ranges += find_ix_ranges(list(np.array(ix).flatten()))\n",
    "    return(flare_ranges,flareFlux)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energyCalculation(flare_ranges,flux_values,binsize=20):\n",
    "    \"\"\"This function will integrate the flux over time to produce the energy for each flare.\n",
    "        Stage: debugging\"\"\"\n",
    "    \n",
    "    energies = []\n",
    "    for flare in flare_ranges: \n",
    "        int_flux = (binsize*flux_values).sum()\n",
    "        energies.append(int_flux)\n",
    "        \n",
    "        #NEXT: don't forget to calculate errors\n",
    "        \n",
    "    return(energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdf929fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlareTable(cleaned_data,flare_ranges,flareFlux,energies):\n",
    "    \"\"\"This function will build a table of all flares.\n",
    "        Stage: debugging\"\"\"\n",
    "    \n",
    "    #Generate quiescent and flaring curves in order to index time values\n",
    "    curves = generate_curves(cleaned_data)\n",
    "    flaring = curves[1]\n",
    "    \n",
    "    #Create empty lists to use as columns for table\n",
    "\n",
    "    tstart = []\n",
    "    tstop = []\n",
    "    duration = []\n",
    "    energy = []\n",
    "    \n",
    "    #Iterate through each individual flare in flare ranges to get values, append to corresponding list\n",
    "    for flare in flare_ranges: \n",
    "        ind_tstart = flare[0]\n",
    "        ind_tstop = flare[-1]\n",
    "        ind_duration = flare[-1]-flare[0]\n",
    "        ind_energy = energies[flare]\n",
    "        tstart.append(ind_tstart)\n",
    "        duration.append(ind_duration)\n",
    "        energy.append(ind_energy)\n",
    "    #Label flares    \n",
    "    flareID = [range(len(flare_ranges))] \n",
    "    \n",
    "    #Build flare table\n",
    "    flareTable = pd.DataFrame({\n",
    "                                \"ID\": flareID,\n",
    "                                \"Start Time\": tstart,\n",
    "                                \"Stop Time\": tstop,\n",
    "                                \"Duration\": duration,\n",
    "                                \"Total Energy\": energy\n",
    "    })\n",
    "    \n",
    "    return(flareTable)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa3c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_FlarePlots(flareTable, cleaned_data,flare_ix):\n",
    "    \"\"\"This function will create plots of all detected flares.\n",
    "        Parameter flare_ix will be indices of flares that can be \n",
    "        used to plot from cleaned data.\n",
    "        Stage: very rough working draft\"\"\"\n",
    "    \n",
    "    for row in flareTable: \n",
    "        #Set ranges to give 3 mins of data on either side of flare\n",
    "        time_range = (flareTable[\"Start Time\"] - 3 mins (-12 index),flareTable[\"Stop Time\"] + 3 mins (+12index))\n",
    "        flux_range = (flare_ix - 12index, flare_ix + 12index)\n",
    "        \n",
    "        plt.xlabel(\"Time (UTC)\")\n",
    "        plt.ylabel(\"Flux (e/s)\")\n",
    "        plt.figure(figsize=(14,3))\n",
    "        plt.text(location, \"Time:\" flareTable[\"Start Time\"])\n",
    "        plt.text(location, \"Duration:\"flareTable[\"Duration\"])\n",
    "        plt.text(location, \"Energy:\"flareTable[\"Total Energy\"])\n",
    "        plt.plot(time_range, flux_range)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48e4e077",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m q_curve \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m curve \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[43mflareFinder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurve\u001b[49m\u001b[43m,\u001b[49m\u001b[43mq_curve\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36mflareFinder\u001b[0;34m(curve, q_curve, sig)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     36\u001b[0m     consec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcurve\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix_range\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlux\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39mcurve\u001b[38;5;241m.\u001b[39miloc[ix_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlux\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m: \u001b[38;5;66;03m#don't understand this statement much, how do I get it to break correctly?\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     39\u001b[0m ix_range \u001b[38;5;241m=\u001b[39m ix_range \u001b[38;5;241m+\u001b[39m [ix_range[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tess_swift_afpsc/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tess_swift_afpsc/lib/python3.9/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tess_swift_afpsc/lib/python3.9/site-packages/pandas/core/indexing.py:1452\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1450\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "TESSDATA = '/Users/katborski/Documents/GitHub/AFPSC/TESS/tess2021232031932-s0042-0000000250081915-0213-a_fast-lc.fits'\n",
    "cleaned_data = dataClean(TESSDATA)\n",
    "\n",
    "dataset = generate_Qcurve(cleaned_data)\n",
    "q_curve = dataset[0]\n",
    "curve = dataset[1]\n",
    "\n",
    "flareFinder(curve,q_curve,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b1938d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5f8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfea180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7aafc17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602dc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
